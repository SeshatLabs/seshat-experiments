{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### TRANSACTION GRAPH ############\n",
    "# Read datasets\n",
    "transactions = pd.read_csv('dataset/user_transactions.csv')\n",
    "contract_addresses = pd.read_csv('dataset/contract_addresses.csv').address.tolist()\n",
    "transactions = transactions[:1000]\n",
    "\n",
    "print(\"txs and contracts loaded\")\n",
    "# Neo4j connection setup\n",
    "uri = \"bolt://localhost:8092\"  # default connection URI for local Neo4j\n",
    "username = \"neo4j\"\n",
    "password = \"uWBOzDTQLXJLiFFF\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def sanitize_function_name(name):\n",
    "    # Replace any non-alphanumeric character with an underscore\n",
    "    sanitized_name = re.sub(r'\\W+', '_', name)\n",
    "    \n",
    "    # Ensure it starts with a letter\n",
    "    if not sanitized_name[0].isalpha():\n",
    "        sanitized_name = 'F_' + sanitized_name\n",
    "\n",
    "    return sanitized_name\n",
    "\n",
    "def create_transaction(tx, row):\n",
    "    # Check if 'from' and 'to' addresses are contracts or users\n",
    "    from_type = 'Contract' if row['from'] in contract_addresses else 'User'\n",
    "    to_type = 'Contract' if row['to'] in contract_addresses else 'User'\n",
    "\n",
    "    # Check if functionName is empty or NaN\n",
    "    raw_func_name = row['functionName'] if pd.notna(row['functionName']) and row['functionName'] != '' else 'UNKNOWN'\n",
    "    func_name = sanitize_function_name(raw_func_name)\n",
    "    \n",
    "    # Cypher query\n",
    "    #TODO: when creating contract nodes, find it's name and add as node feature, then going to contract level we can have custom generated tag from contract content\n",
    "    query = (\n",
    "        f\"MERGE (a:{from_type} {{address: $from_address}}) \"\n",
    "        f\"MERGE (b:{to_type} {{address: $to_address}}) \"\n",
    "        f\"CREATE (a)-[r:{func_name} {{input: $input, timeStamp: $timeStamp}}]->(b)\"\n",
    "    )\n",
    "    tx.run(query, from_address=row['from'], to_address=row['to'], input=row['input'], timeStamp=row['timeStamp'])\n",
    "\n",
    "# Execute transaction for each row in the transactions dataframe\n",
    "with driver.session() as session:\n",
    "    for _, row in tqdm(transactions.iterrows()):\n",
    "        session.write_transaction(create_transaction, row)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# GRAPH CONVOLUTIONAL NETWORK ####################\n",
    "# user_transactions = pd.read_csv('dataset/user_transactions.csv')\n",
    "# contract_addresses_with_names = pd.read_csv('dataset/contract_addresses_with_name.csv')\n",
    "# user_transactions = user_transactions[:100]\n",
    "\n",
    "# print('data has been loaded')\n",
    "\n",
    "edge_index = []\n",
    "edge_weights = defaultdict(int)\n",
    "edge_features = []\n",
    "node_to_id = {}\n",
    "current_id = 0\n",
    "\n",
    "def get_node_name(address):\n",
    "    # Check if address exists in contract_addresses_with_names\n",
    "    name = contract_addresses_with_names[contract_addresses_with_names['contract_address'] == address]['contract_name']\n",
    "    if name.empty:\n",
    "        return address\n",
    "    else:\n",
    "        return name.values[0]\n",
    "\n",
    "for idx, row in tqdm(user_transactions.iterrows(), total = len(user_transactions)):\n",
    "    from_name = get_node_name(row['from'])\n",
    "    to_name = get_node_name(row['to'])\n",
    "    \n",
    "    # Assign an id to each unique address/name\n",
    "    if from_name not in node_to_id:\n",
    "        node_to_id[from_name] = current_id\n",
    "        current_id += 1\n",
    "    \n",
    "    if to_name not in node_to_id:\n",
    "        node_to_id[to_name] = current_id\n",
    "        current_id += 1\n",
    "    \n",
    "    #TODO: We supposed for same contract call always the function_name is the same\n",
    "    # if [node_to_id[from_name], node_to_id[to_name]] not in edge_index:\n",
    "    edge_index.append([node_to_id[from_name], node_to_id[to_name]])\n",
    "    edge_features.append(row['functionName'])\n",
    "    edge_weights[(from_name, to_name)] += 1\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "#edge_weights = [edge_weights[tuple(edge)] for edge in edge_index.numpy().T]\n",
    "edge_weights = torch.tensor([edge_weights[tuple(edge)] for edge in edge_index.numpy().T], dtype=torch.float)\n",
    "\n",
    "\n",
    "print('1')\n",
    "\n",
    "class SimpleGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(SimpleGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "def get_predictions(model, x, edge_index, edge_weights):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        node_embeddings = model(x, edge_index, edge_weights)\n",
    "    source_embeddings = node_embeddings[edge_index[0]]\n",
    "    target_embeddings = node_embeddings[edge_index[1]]\n",
    "    return (source_embeddings * target_embeddings).sum(-1)\n",
    "\n",
    "# Assuming x is the input node features, which you haven't provided.\n",
    "# If you don't have node features, you can simply use an identity matrix.\n",
    "x = torch.eye(len(node_to_id))\n",
    "print(x.size())\n",
    "\n",
    "model = SimpleGCN(x.size(1), 16)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, x, edge_index, edge_weights, epochs=100):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        preds = get_predictions(model, x, edge_index, edge_weights)\n",
    "        print(preds.shape)\n",
    "        break\n",
    "#         loss = criterion(preds, torch.tensor(edge_weights, dtype=torch.float))\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         losses.append(loss.item())\n",
    "        \n",
    "#         # Print every 10 epochs\n",
    "#         if epoch % 10 == 0:\n",
    "#             print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item()}\")\n",
    "    \n",
    "#     return losses\n",
    "\n",
    "# losses = train(model, x, edge_index, edge_weights)\n",
    "\n",
    "# # Plot the losses\n",
    "# plt.plot(losses)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
