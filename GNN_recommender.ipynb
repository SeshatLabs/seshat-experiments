{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo4j torch_geometric torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from neo4j import GraphDatabase\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########### TRANSACTION GRAPH ############\n",
    "# Read datasets\n",
    "transactions = pd.read_csv('dataset/user_transactions.csv')\n",
    "contract_addresses = pd.read_csv('dataset/contract_addresses.csv').address.tolist()\n",
    "transactions = transactions[:1000]\n",
    "\n",
    "print(\"txs and contracts loaded\")\n",
    "# Neo4j connection setup\n",
    "uri = \"bolt://localhost:8092\"  # default connection URI for local Neo4j\n",
    "username = \"neo4j\"\n",
    "password = \"uWBOzDTQLXJLiFFF\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def sanitize_function_name(name):\n",
    "    # Replace any non-alphanumeric character with an underscore\n",
    "    sanitized_name = re.sub(r'\\W+', '_', name)\n",
    "    \n",
    "    # Ensure it starts with a letter\n",
    "    if not sanitized_name[0].isalpha():\n",
    "        sanitized_name = 'F_' + sanitized_name\n",
    "\n",
    "    return sanitized_name\n",
    "\n",
    "def create_transaction(tx, row):\n",
    "    # Check if 'from' and 'to' addresses are contracts or users\n",
    "    from_type = 'Contract' if row['from'] in contract_addresses else 'User'\n",
    "    to_type = 'Contract' if row['to'] in contract_addresses else 'User'\n",
    "\n",
    "    # Check if functionName is empty or NaN\n",
    "    raw_func_name = row['functionName'] if pd.notna(row['functionName']) and row['functionName'] != '' else 'UNKNOWN'\n",
    "    func_name = sanitize_function_name(raw_func_name)\n",
    "    \n",
    "    # Cypher query\n",
    "    #TODO: when creating contract nodes, find it's name and add as node feature, then going to contract level we can have custom generated tag from contract content\n",
    "    query = (\n",
    "        f\"MERGE (a:{from_type} {{address: $from_address}}) \"\n",
    "        f\"MERGE (b:{to_type} {{address: $to_address}}) \"\n",
    "        f\"CREATE (a)-[r:{func_name} {{input: $input, timeStamp: $timeStamp}}]->(b)\"\n",
    "    )\n",
    "    tx.run(query, from_address=row['from'], to_address=row['to'], input=row['input'], timeStamp=row['timeStamp'])\n",
    "\n",
    "# Execute transaction for each row in the transactions dataframe\n",
    "with driver.session() as session:\n",
    "    for _, row in tqdm(transactions.iterrows()):\n",
    "        session.write_transaction(create_transaction, row)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# GRAPH CONVOLUTIONAL NETWORK ####################\\\n",
    "contract_names = pd.read_csv('dataset/contract_addresses_with_name.csv')\n",
    "all_contracts = pd.read_csv('dataset/contract_addresses.csv')\n",
    "contract_names = contract_names[contract_names['contract_name'].notna()]\n",
    "user_transactions_df = pd.read_csv('dataset/user_transactions.csv')\n",
    "# user_transactions_df = user_transactions_df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1616/1738651 [00:19<5:45:44, 83.74it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m         \u001b[39mreturn\u001b[39;00m (name\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mcontract\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m tqdm(user_transactions_df\u001b[39m.\u001b[39miterrows(), total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(user_transactions_df)):\n\u001b[1;32m     23\u001b[0m     from_name, from_type \u001b[39m=\u001b[39m get_node_name(row[\u001b[39m'\u001b[39m\u001b[39mfrom\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     24\u001b[0m     to_name, to_type \u001b[39m=\u001b[39m get_node_name(row[\u001b[39m'\u001b[39m\u001b[39mto\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/pandas/core/frame.py:1399\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1397\u001b[0m using_cow \u001b[39m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1398\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues):\n\u001b[0;32m-> 1399\u001b[0m     s \u001b[39m=\u001b[39m klass(v, index\u001b[39m=\u001b[39;49mcolumns, name\u001b[39m=\u001b[39;49mk)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1400\u001b[0m     \u001b[39mif\u001b[39;00m using_cow \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mis_single_block:\n\u001b[1;32m   1401\u001b[0m         s\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39madd_references(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/pandas/core/series.py:509\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    507\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[1;32m    511\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/pandas/core/construction.py:569\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    567\u001b[0m subarr \u001b[39m=\u001b[39m data\n\u001b[1;32m    568\u001b[0m \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[0;32m--> 569\u001b[0m     subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(data)\n\u001b[1;32m    571\u001b[0m \u001b[39mif\u001b[39;00m subarr \u001b[39mis\u001b[39;00m data \u001b[39mand\u001b[39;00m copy:\n\u001b[1;32m    572\u001b[0m     subarr \u001b[39m=\u001b[39m subarr\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1178\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n\u001b[1;32m   1175\u001b[0m \u001b[39m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m \u001b[39m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[39m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1178\u001b[0m \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49mmaybe_convert_objects(  \u001b[39m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1179\u001b[0m     value,\n\u001b[1;32m   1180\u001b[0m     \u001b[39m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1181\u001b[0m     \u001b[39m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1182\u001b[0m     convert_numeric\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1183\u001b[0m     convert_period\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1184\u001b[0m     convert_interval\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1185\u001b[0m     convert_timedelta\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1186\u001b[0m     convert_datetime\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1187\u001b[0m     dtype_if_all_nat\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mM8[ns]\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1188\u001b[0m )\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2445\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/sean2/venv/lib/python3.9/site-packages/numpy/core/numeric.py:342\u001b[0m, in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[39mreturn\u001b[39;00m _full_with_like(shape, fill_value, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder, like\u001b[39m=\u001b[39mlike)\n\u001b[1;32m    341\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 342\u001b[0m     fill_value \u001b[39m=\u001b[39m asarray(fill_value)\n\u001b[1;32m    343\u001b[0m     dtype \u001b[39m=\u001b[39m fill_value\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    344\u001b[0m a \u001b[39m=\u001b[39m empty(shape, dtype, order)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "user_contract_df = pd.read_parquet(\"dataset/user_contract_rating.parquet\")\n",
    "user_contract_df = user_contract_df[ user_contract_df['item'] != '']\n",
    "user_contract_df = user_contract_df['item'].isin(contract_names['contract_name'])\n",
    "all_contracts_set = set(all_contracts['address'])\n",
    "print(len(user_contract_df))\n",
    "\n",
    "# TODO: add node features into node embeddings\n",
    "\n",
    "edge_index = []\n",
    "edge_weights = defaultdict(int)\n",
    "edge_features = []\n",
    "node_to_id = {}\n",
    "node_type_dict = {'user': 0, 'contract': 1}\n",
    "node_features = []\n",
    "current_id = 0\n",
    "\n",
    "\n",
    "def get_node_name(address):\n",
    "    # Check if address exists in contract_addresses_with_names\n",
    "    name = contract_names[contract_names['contract_address'] == address]['contract_name']\n",
    "    if name.empty:\n",
    "        return ('unknown', 'contract') if address in all_contracts_set else (address, 'user')\n",
    "    else:\n",
    "        return (name.values[0], 'contract')\n",
    "\n",
    "for idx, row in tqdm(user_contract_df.iterrows(), total = len(user_contract_df)):\n",
    "    # from_name, from_type = get_node_name(row['from'])\n",
    "    # to_name, to_type = get_node_name(row['to'])\n",
    "    user_node, item_node = row['user'], row['item']\n",
    "\n",
    "    # if (from_name == 'unknown' and from_type == 'contract') or (to_name == 'unknown' and to_type == 'contract'): continue # skip rows with unknown contract name (since we don't have their code too)\n",
    "\n",
    "    if user_node not in node_to_id:\n",
    "        node_to_id[user_node] = current_id\n",
    "        node_features.append(node_type_dict['user'])\n",
    "        current_id += 1\n",
    "    \n",
    "    if item_node not in node_to_id:\n",
    "        node_to_id[item_node] = current_id\n",
    "        # node_features.append([node_type_dict['contract'], item_node]) # Have contract name as another feature besides type\n",
    "        node_features.append(node_type_dict['contract'])\n",
    "        current_id += 1\n",
    "    \n",
    "    #TODO: defferentiate same from or to node but with diff function_name\n",
    "    edge = [node_to_id[user_node], node_to_id[item_node]]\n",
    "    if edge not in edge_index:\n",
    "        edge_index.append(edge)\n",
    "        edge_features.append(row['functionName'])\n",
    "        edge_weights[(user_node, item_node)] += 1\n",
    "\n",
    "\n",
    "x = torch.tensor(node_features, dtype=torch.long).unsqueeze(1) # Converting node features to tensor\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_weights = torch.tensor([edge_weights[tuple(edge)] for edge in edge_index.numpy().T], dtype=torch.float)\n",
    "\n",
    "\n",
    "# print('1')\n",
    "\n",
    "class SimpleGCN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(SimpleGCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
    "        return x.squeeze(-1)\n",
    "\n",
    "# def get_predictions(model, x, edge_index, edge_weights):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         node_embeddings = model(x, edge_index, edge_weights)\n",
    "#     source_embeddings = node_embeddings[edge_index[0]]\n",
    "#     target_embeddings = node_embeddings[edge_index[1]]\n",
    "#     return (source_embeddings * target_embeddings).sum(-1)\n",
    "\n",
    "# model = SimpleGCN(x.size(1), 16)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# def train(model, x, edge_index, edge_weights, epochs=100):\n",
    "#     model.train()\n",
    "#     losses = []\n",
    "#     for epoch in range(epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         preds = get_predictions(model, x, edge_index, edge_weights)\n",
    "#         print(preds.shape)\n",
    "#         break\n",
    "# #         loss = criterion(preds, torch.tensor(edge_weights, dtype=torch.float))\n",
    "# #         loss.backward()\n",
    "# #         optimizer.step()\n",
    "        \n",
    "# #         losses.append(loss.item())\n",
    "        \n",
    "# #         # Print every 10 epochs\n",
    "# #         if epoch % 10 == 0:\n",
    "# #             print(f\"Epoch {epoch}/{epochs}, Loss: {loss.item()}\")\n",
    "    \n",
    "# #     return losses\n",
    "\n",
    "# # losses = train(model, x, edge_index, edge_weights)\n",
    "\n",
    "# # # Plot the losses\n",
    "# # plt.plot(losses)\n",
    "# # plt.xlabel('Epoch')\n",
    "# # plt.ylabel('Loss')\n",
    "# # plt.title('Training Loss')\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      address  tx_count\n",
      "0  0x40a4294f8ea7cac3d93336b9a70c758c03535508         3\n",
      "1  0x0ea17d0698cbf66b2cdda3eb27ef2b7c7d31135e         3\n",
      "2  0x1997b40fea47d66cf2b48c5fab960c8dab80df7d         3\n",
      "3  0xb2914f6db3ad77e5302d9b6b578c4119873e9b2e         3\n",
      "4  0x1d025fd2547d04f1308757d43415ac628c402dcb         3\n"
     ]
    }
   ],
   "source": [
    "print(all_contracts[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sean2",
   "language": "python",
   "name": "sean2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
